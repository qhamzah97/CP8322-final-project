{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11620dd3",
   "metadata": {},
   "source": [
    "This section defines the overall model of the system introduced by the paper along with each individual component that makes up the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45046993",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import itertools\n",
    "import math\n",
    "import numpy as np\n",
    "import os\n",
    "import pdb\n",
    "from scipy import signal\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c528b2c",
   "metadata": {},
   "source": [
    "![Overall System](system.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4527b2c3",
   "metadata": {},
   "source": [
    "The figure above is an overview of the system that the researchers implemented for transductive inference. The system consists of three modules: a feature extractor, an rPPG estimator and a synthetic gradient generator. In this section, each of the individual modules have been fleshed out along with the ordinal regression loss, and are combined together to create the overall system"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4101e28e",
   "metadata": {},
   "source": [
    "# Sub Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6087a04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ed62e5",
   "metadata": {},
   "source": [
    "![Layer Breakdown](system_layer_breakdown.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ec41c68",
   "metadata": {},
   "source": [
    "The individual modules are created using the layer breakdown that can be seen above"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c12d719",
   "metadata": {},
   "source": [
    "## Convolutional Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ed1c5e",
   "metadata": {},
   "source": [
    "Used for transductive learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce55782",
   "metadata": {},
   "source": [
    "| Layer | Output Size | Kernel Size |\n",
    "| :-: | :-: | :-: |\n",
    "| Conv2DBlock | 60x32x32x32 | 3x3 |\n",
    "| Conv2DBlock | 60x48x16x16 | 3x3 |\n",
    "| Conv2DBlock | 60x64x8x8 | 3x3 |\n",
    "| Conv2DBlock | 60x80x4x4 | 3x3 |\n",
    "| Conv2DBlock | 60x120x2x2 | 3x3 |\n",
    "| AvgPool | 60x120 | 2x2 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df711cf8",
   "metadata": {},
   "source": [
    "The Conv2DBlocks are composed of a Conv2D, Batchnorm, average pooling and ReLU blocks\n",
    "\n",
    "Output size is defined as T * Channels * K * K where\n",
    ">T - number of input stream frames <br>\n",
    "    channels - number of channels <br>\n",
    "    KxK - size of the cropped and reshaped input face image <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36d36b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Convolutional_Encoder(nn.Module):\n",
    "    def _init_(self, no_input_channel, isTrain, device):\n",
    "        \n",
    "        # Supercharge the Convolutional_Encoder class so that it can inherit from itself\n",
    "        # This way individual layers can be defined within the class as per the image 'Layer Breakdown'\n",
    "        super(Convolutional_Encoder, self)._init_()\n",
    "        \n",
    "        \n",
    "        # Define the convolutional layers via the number of input nodes, number of output nodes,\n",
    "        # kernel size, stride and padding\n",
    "        self.conv = nn.Conv3d\n",
    "        # Define kernel size, stride and padding\n",
    "        kernel = (1, 3, 3)\n",
    "        stride = (1, 1, 1)\n",
    "        padding = (0, 1, 1)\n",
    "        # Number of output nodes in previous layer = number of input nodes in next layer\n",
    "        # layer 1\n",
    "        self.conv1 = self.conv(no_input_channel, 32, kernel, stride, padding)\n",
    "        # layer 2\n",
    "        self.conv2 = self.conv(32, 48, kernel, stride, padding)\n",
    "        # layer 3\n",
    "        self.conv3 = self.conv(48, 64, kernel, stride, padding)\n",
    "        # layer 4\n",
    "        self.conv4 = self.conv(64, 80, kernel, stride, padding)\n",
    "        # layer 5\n",
    "        self.conv5 = self.conv(80, 120, kernel, stride, padding)\n",
    "        \n",
    "        \n",
    "        # Define the BatchNorm layer\n",
    "        # layer 1\n",
    "        self.bn1 = nn.BatchNorm3d(32)\n",
    "        # layer 2\n",
    "        self.bn2 = nn.BatchNorm3d(48)\n",
    "        # layer 3\n",
    "        self.bn3 = nn.BatchNorm3d(64)\n",
    "        # layer 4\n",
    "        self.bn4 = nn.BatchNorm3d(80)\n",
    "        # layer 5\n",
    "        self.bn5 = nn.BatchNorm3d(120)\n",
    "        \n",
    "        \n",
    "        # Defining the pooling window (value recieved from the paper)\n",
    "        pool = (1, 2, 2)\n",
    "        \n",
    "        \n",
    "        # Defining the ReLU block\n",
    "        self.ReLU = nn.ReLU(inplace=True)\n",
    "        \n",
    "    \n",
    "    # Forward propagation\n",
    "    def forward(self, x):\n",
    "        # x is the input face image\n",
    "        window = x.shape[1]\n",
    "        # Arrange the tensor according to the paper's ordering\n",
    "        # x = x.permute(0, 2, 1, 3, 4)\n",
    "        \n",
    "        # Implementing 5 seperate Conv2DBlock\n",
    "        # Conv2DBlock = conv2D + BatchNorm + Average Pooling in 3D space + ReLU\n",
    "        # 1st Conv2DBlock\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = avg_pool3d(x, pool)\n",
    "        x = self.ReLU(x)\n",
    "        # 2nd Conv2DBlock\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = avg_pool3d(x, pool)\n",
    "        x = self.ReLU(x)\n",
    "        # 3rd Conv2DBlock\n",
    "        x = self.conv3(x)\n",
    "        x = self.bn3(x)\n",
    "        x = avg_pool3d(x, pool)\n",
    "        x = self.ReLU(x)\n",
    "        # 4th Conv2DBlock\n",
    "        x = self.conv4(x)\n",
    "        x = self.bn4(x)\n",
    "        x = avg_pool3d(x, pool)\n",
    "        x = self.ReLU(x)\n",
    "        # 5th Conv2DBlock\n",
    "        x = self.conv5(x)\n",
    "        x = self.bn5(x)\n",
    "        x = avg_pool3d(x, pool)\n",
    "        x = self.ReLU(x)\n",
    "        \n",
    "        # Implementing the AvgPool Block\n",
    "        x = F.adaptive_avg_pool3d(x, (window, 1, 1))\n",
    "        \n",
    "        # Rearrange the tensor to have the same ordering as before\n",
    "        # x = x.permute(0, 2, 1, 3, 4)\n",
    "        \n",
    "        # Reshaping of tensor to our original input\n",
    "        x = x.reshape(x.size(0), x.size(1), -1)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    # Backward propagation to update the weights of the gradient\n",
    "    def return_grad(self):\n",
    "        c1 = self.conv1.weight.grad.data.clone()\n",
    "        b1 = self.bn1.weight.grad.data.clone()\n",
    "        c2 = self.conv2.weight.grad.data.clone()\n",
    "        b2 = self.bn2.weight.grad.data.clone()\n",
    "        c3 = self.conv3.weight.grad.data.clone()\n",
    "        b3 = self.bn3.weight.grad.data.clone()\n",
    "        c4 = self.conv4.weight.grad.data.clone()\n",
    "        b4 = self.bn4.weight.grad.data.clone()\n",
    "        c5 = self.conv5.weight.grad.data.clone()\n",
    "        b5 = self.bn5.weight.grad.data.clone()\n",
    "        \n",
    "        return{'c1':c1, 'c2':c2, 'c3':c3, 'c4':c4, 'c5':c5,\n",
    "               'b1':b1, 'b2':b2, 'b3':b3, 'b4':b4, 'b5':b5}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db8fb46",
   "metadata": {},
   "source": [
    "## rPPG Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1b9f6f",
   "metadata": {},
   "source": [
    "Used to infer the rPPG signal <br>\n",
    "Posed as an Ordinal Regression Task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792fa9df",
   "metadata": {},
   "source": [
    "| Layer | Output Size |\n",
    "| :-: | :-: |\n",
    "| Bidirectional LSTM | 60x120\n",
    "| Linear | 60x80 |\n",
    "| Ordinal | 60x40 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836ffb28",
   "metadata": {},
   "source": [
    "Output size is defined as T * Channels where\n",
    ">T - number of input stream frames <br>\n",
    "    channels - number of channels <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b4762a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class rPPG_Estimator(nn.Module):\n",
    "    def _init_(self, no_input_channel, num_layers, isTrain, device, num_classes=40, h=None, c=None):\n",
    "        \n",
    "        # Supercharge the rPPG_Estimator class so that it can inherit from itself\n",
    "        super(rPPG_Estimator, self)._init_()\n",
    "        \n",
    "        # LSTM layer\n",
    "        self.lstm = nn.LSTM(input_size=120, hidden_size=60, num_layers=num_layers, batch_first=True, bidirectional=True)\n",
    "        # Linear Layer\n",
    "        self.lin = nn.Linear(120, 80)\n",
    "        # Ordinal Layer\n",
    "        self.ord = OrdinalRegressionLayer()\n",
    "        \n",
    "        # Accounting for spatial and temporal features\n",
    "        self.h, self.c = h, c\n",
    "    \n",
    "    \n",
    "    # Forward propagation\n",
    "    def forward(self, x):\n",
    "        # Flatten the input lstm matrix into a vector\n",
    "        self.lstm.flatten_parameters()\n",
    "        # LSTM layer\n",
    "        x, (self.h, self.c) = self.lstm(x, (self.h.data, self.c.data))\n",
    "        # Linear layer\n",
    "        x = self.lin(x)\n",
    "        # Ordinal layer - used to gain the condition and estimator variable\n",
    "        # condition can be either 0 or 1 denoting whether our samples falls within the correct segment or not\n",
    "        # estimator is our rPPG estimation\n",
    "        condition, estimator = self.orl(x)\n",
    "        condition = condition.squeeze(2)\n",
    "        return condition, estimator\n",
    "    \n",
    "    def feed_hc(self, date):\n",
    "        self.h = data[0].data\n",
    "        self.c = data[1].data\n",
    "        \n",
    "    # Backward propagation to update weights of the gradient\n",
    "    def return_grad(self):\n",
    "        dt_lstm = {}\n",
    "        lin_grad = self.lin.weight.grad.data.clone()\n",
    "        list_lstm = self.lstm._all_weights\n",
    "        for x in list_lstm:\n",
    "            for y in x:\n",
    "                dt_lstm[x] = self.lstm._parameters[x].grad.data.clone()\n",
    "        return {lin_grad, dt_lstm}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "149c69ff",
   "metadata": {},
   "source": [
    "### Ordinal Regression Loss\n",
    "Setting the Ordinal Regression Loss through a custom function OrdinalRegressionLayer() - introduced by authors of 'Predicting progression of alzheimers disease using ordinal regression'<br>\n",
    "Code pulled in from the GitHub repository of the paper's researchers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b9593b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OrdinalRegressionLayer(nn.Module):\n",
    "    def _init_(self):\n",
    "        super(OrdinalRegressionLayer, self)._init_()\n",
    "        \n",
    "    def forward (self, x):\n",
    "        \"\"\"\n",
    "        :param x: N X H X W X C, N is batch_size, C is channels of features\n",
    "        :return: ord_labels is ordinal outputs for each spatial locations, \n",
    "        size is N x H X W X C (C = 2K, K is interval of SID)\n",
    "        decode_label is the ordinal labels for each position of Image I\n",
    "        \"\"\"\n",
    "        x = x.permute(0, 2, 1)\n",
    "        N, C, W = x.size()\n",
    "        ord_num = C\n",
    "        \n",
    "        \"\"\"\n",
    "        replace iter with matrix operation\n",
    "        fast speed methods\n",
    "        \"\"\"\n",
    "        A = x[:, ::2, :].clone()\n",
    "        B = x[:, 1::2, :].clone()\n",
    "        A = A.view(N, 1, ord_num * W)\n",
    "        B = B.view(N, 1, ord_num * W)\n",
    "        C = torch.cat((A, B), dim=1)\n",
    "        # prevent nans\n",
    "        C = torch.clamp(C, min=1e-8, max=1e8)\n",
    "        ord_c = F.softmax(C, dim=1)\n",
    "        \n",
    "        ord_c1 = ord_c[:, 1, :].clone()\n",
    "        ord_c1 = ord_c1.view(-1, ord_num, W)\n",
    "        decode_c = torch.sum((ord_c1 > 0.5), dim=1).view(-1, 1, W)\n",
    "        ord_c1 = ord_c1.permute(0, 2, 1)\n",
    "        decode_c = decode_c.permute(0, 2, 1)\n",
    "        return decode_c, ord_c1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd99710",
   "metadata": {},
   "source": [
    "## Synthetic Gradient Generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8366bde6",
   "metadata": {},
   "source": [
    "Used to infer the rPPG signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7711555d",
   "metadata": {},
   "source": [
    "| Layer | Output Size | Kernel Size |\n",
    "| :-: | :-: | :-: |\n",
    "| Conv1DBlock | 40x120 | 3x3 |\n",
    "| Conv1DBlock | 20x120 | 3x3 |\n",
    "| Conv1DBlock | 40x120 | 3x3 |\n",
    "| Conv1DBlock | 60x120 | 3x3 |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef4118d",
   "metadata": {},
   "source": [
    "The Conv1DBlocks are composed of a Conv1D, Batchnorm and ReLU blocks\n",
    "\n",
    "Output size is defined as T * Channels where\n",
    ">T - number of input stream frames <br>\n",
    "    channels - number of channels <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec4e7f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Synthetic_Gradient_Generator(nn.Module):\n",
    "    def _init_(self, number_input_channels, isTrain, device):\n",
    "        \n",
    "        # Supercharge the Synthetic_Gradient_Generator class so that it can inherit from itself\n",
    "        super(Synthetic_Gradient_Generator, self)._init_()\n",
    "        \n",
    "        # layer 1\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv1d(60, 40, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm(40),\n",
    "            nn.ReLU())\n",
    "        # layer 2\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv1d(40, 20, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm(20),\n",
    "            nn.ReLU())\n",
    "        # layer 3\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv1d(20, 40, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm(40),\n",
    "            nn.ReLU())\n",
    "        # layer 4\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.ConvTranspose1d(40, 60, kernel_size=3, padding=1))\n",
    "    \n",
    "    # Forward propagation\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2275c68",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
