{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cfb8dec",
   "metadata": {},
   "source": [
    "This file incldues the data processing and functions required to initialize our training conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee9477f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the general packages needed\n",
    "from __future__ import print_function\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pdb\n",
    "import pickle\n",
    "import os\n",
    "import random\n",
    "from scipy import signal\n",
    "from scipy.signal import butter, lfilter\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24445463",
   "metadata": {},
   "source": [
    "# Data Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516989bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50d073c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Set_Function():\n",
    "    \n",
    "    # Define the function constructor\n",
    "    def _init_(self, rate=30.0, display_port=8093):\n",
    "        # setting the fps to 30Hz as per mentioned in the paper\n",
    "        self.fps = rate\n",
    "    \n",
    "    # CHROM method - derived from the paper 'Robust pulse rate from chrominance-based rppg'\n",
    "    # POS method - derived from the paper 'Algorithmic principles of remote ppg'\n",
    "    \n",
    "    # Defining a bandpass to filter the input signal recieved from video dataset\n",
    "    def butter_bandpass_filter(data, lowpass, highpass, fs, order=5):\n",
    "        \n",
    "        # Nyquist frequency = 1/2 the sampling rate\n",
    "        nyq = fs/2\n",
    "        low = lowpass/nyq\n",
    "        high = highpass/nyq\n",
    "        \n",
    "        # Implementing the Butterworth bandpass via the butter() function\n",
    "        b, a = butter(order, [low, high], btype='band')    \n",
    "        \n",
    "        # Applying a filter to the Butterworth bandpass\n",
    "        y = signal.filtfilt(b, a, data, method='pad')\n",
    "        return y\n",
    "    \n",
    "    # Defining the tesing function to run test configuration of the model\n",
    "    # Take in the model, test dataset, index and epoch number to evaluate test loss\n",
    "    def testing(opt, model, test_set, index, epoch):\n",
    "        # Obtain results and loss from current model\n",
    "        results, rPPG = model.get_current_results(0)\n",
    "        loss = model.get_current_losses(0)\n",
    "        data = test_set[0, 0]\n",
    "        \n",
    "        # Set the input for the test data\n",
    "        model.set_input(test_data)\n",
    "        model.few_shotloss_test(epoch)\n",
    "        \n",
    "        # Get the updated results and loss\n",
    "        new_results, new_rPPG = model.get_current_results(1)\n",
    "        new_loss = model.get_current_losses(1)\n",
    "        \n",
    "        # Train the model\n",
    "        model.train()\n",
    "        \n",
    "        return loss[2], new_loss\n",
    "    \n",
    "    # def amp_equalize\n",
    "    # def get_bpm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d007b586",
   "metadata": {},
   "source": [
    "# Data Preload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6752bd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from sklearn.preprocessing import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2611a383",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseDataset():\n",
    "    def _init_(self, opt, isTrain):\n",
    "        self.isTrain = isTrain\n",
    "        self.opt = opt\n",
    "        self.length = 0\n",
    "        \n",
    "        # Loading data recieved from researchers repo\n",
    "        data = torch.load('example.path')\n",
    "        \n",
    "        # Set the mask, facial and ppg data from beginning of dataset if training is set to true\n",
    "        # Else grab from end if training is false\n",
    "        if self.isTrain:\n",
    "            self.maskset = data['mask'][:5]\n",
    "            self.dataset = data['image'][:5]\n",
    "            self.ppgset = data['ppg'][:5]\n",
    "            self.tasks = len(self.dataset)\n",
    "            for i in range(len(self.dataset)):\n",
    "                self.tasks_len = self.dataset[i].shape[0]\n",
    "        else:\n",
    "            self.maskset = data['mask'][-1:]\n",
    "            self.dataset = data['image'][-1:]\n",
    "            self.ppgset = data['ppg'][-1:]\n",
    "            self.tasks = 1\n",
    "            self.tasks_len = self.dataset[0].shape[0]\n",
    "        \n",
    "        for i in range(len(self.ppgset)):\n",
    "            self.length += self.ppgset[i].shape[0] - self.opt.win_size\n",
    "            \n",
    "    \n",
    "    # def _getitem_\n",
    "    # def _len_\n",
    "    \n",
    "    # Quantize ppg signal into 40 segments ordered by rank \n",
    "    def quantify(self, rppg):\n",
    "        rank = torch.empty(rppg.shape[0], dtype=torch.long)\n",
    "        rppg_max = rppg.max()\n",
    "        rppg_min = rppg.min()\n",
    "        interval = (rppg_max - rppg_min)/39\n",
    "        for i in range(len(rank)):\n",
    "            rank[i] = ((rppg[i] - rppg_min)/interval).round().long()\n",
    "        return rank\n",
    "    \n",
    "    # def baseline_process\n",
    "    # def _call_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3101b74",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1caf8517",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SlideWindowDataLoader():\n",
    "    def _init_(self, opt, isTrain):\n",
    "        self.opt = opt\n",
    "        self.isTrain = isTrain\n",
    "        \n",
    "        # initialize the dataset\n",
    "        # It will be either the train set or test set depending on the value of isTrain \n",
    "        self.data = BaseDataset(opt, isTrain)\n",
    "        self.length = int(len(self.data))\n",
    "        self.num_tasks = self.data.num_tasks\n",
    "        self.task_len = self.data.task_len\n",
    "        \n",
    "        if self.isTrain:\n",
    "            print('train dataset is created')\n",
    "        else:\n",
    "            print('Test dataset is created')\n",
    "        \n",
    "    # def load_data\n",
    "    # def _len_\n",
    "    # def _getitem_\n",
    "    \n",
    "    # Normalize the rppg signal to be within 0 and 1 which will be quantized into 40 segments ordered by rank\n",
    "    def quantify(self, rppg):\n",
    "        rank = torch.empty(rppg.shape[0], dtype=torch.long)\n",
    "        ni = torch.ones(rppg.shape[0], dtype=torch.long)\n",
    "        rppg_max = rppg.max()\n",
    "        rppg_min = rppg.min()\n",
    "        interval = (rppg_max - rppg_min)/39\n",
    "        for i in range(len(rank)):\n",
    "            rank[i] = ((rppg[i] - rppg_min)/interval).round().long()\n",
    "        return rank\n",
    "    \n",
    "    # def _call_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39671520",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
